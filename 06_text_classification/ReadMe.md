## 中文文本分类项目

### 背景介绍
在财经新闻中，有的新闻关注宏观信息，而有的新闻关注非宏观信息。不同的用户关注不同的侧面，如做大宗商品交易的可能更关注宏观信息。因此准确区分宏观新闻和非宏观新闻是一个很实际的需求。

### 数据集介绍
数据集来源是舆情系统中标注的一部分数据，每个元素为一个dict，包含标题（text）和label，0代表非宏观新闻，1代表宏观新闻

路径：`shannon-bootcamp/06_text_classification`

### 要求

1. 使用SVM实现情感分类，特征任选，推荐使用的特征有：字级别的unigram, bigram，词级别的unigram，词性标签等等；
2. 使用pytorch-lightning框架实现情感分类，模型任选，推荐使用的模型有BiLSTM和RoBERTa；
3. F1达到85%以上；
4. 继承TextClassifier，重写classifier方法，实现情感极性的预测。


### 实现过程
1. 首先使用SVM实现情感分类，先对文本分词统计得到训练集所有词语作为特征
   - version1：直接用所有词语作为特征进行SVM拟合，特征数较多达到7000多个，最终效果一般test_F1仅达80%
   - version2：去掉所有停用词，将剩余词语作为特征进行SVM拟合，特征数还有6000多个，test_F1上升2个点达到82%
   - version3：受到之后的词袋模型启发，使用字级别特征进行SVM拟合，特征数2000多个，运行速度大幅提升，test_F1超85%
2. 使用BiLSTM实现情感分类，先对文本分词统计得到训练集所有词语作为特征
   - version1：直接用所有词语作为特征，使用BiLSTM最后的ht输出送入全连接层进行预测，效果一般test_F1仅80%
   - version2：同样用所有词语作为特征，使用BiLSTM所有hidden累加标准化后送入全连接层，效果类似version1，test_F1仅81%
   - version3：受到之后的词袋模型启发，取字作为特征，模型结构采用version1模型，性能得到提升，test_F1达84%
   - version4：受到之后的词袋模型启发，取字作为特征，模型结构采用version1模型，性能得到提升，test_F1达85.4%
3. 使用词袋模型实现情感分类，使用字作为特征，模型结构较为简单将所有字的Embedding累加取平均，然后送入全连接层进行预测，test_F1超过85%，调参过程中发现最高可到86.2%